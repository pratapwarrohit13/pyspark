{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f87b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6c321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('D://DS//pyspark//age.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f761c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|  Rohit|  32|        10| 35000|\n",
      "|  Sneha|  32|        10| 35000|\n",
      "| Anaaya|   4|         0|     0|\n",
      "| Sayali|  28|         5| 25000|\n",
      "|   null|  56|        35| 50000|\n",
      "| Shobha|null|      null|  null|\n",
      "|Harshad|null|      null| 10000|\n",
      "| Milind|  35|         5|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bb04c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|   Name| Age|Salary|\n",
      "+-------+----+------+\n",
      "|  Rohit|  32| 35000|\n",
      "|  Sneha|  32| 35000|\n",
      "| Anaaya|   4|     0|\n",
      "| Sayali|  28| 25000|\n",
      "|   null|  56| 50000|\n",
      "| Shobha|null|  null|\n",
      "|Harshad|null| 10000|\n",
      "| Milind|  35|  null|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Drop Columns \n",
    "df_pyspark.drop('experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9135faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Rohit| 32|        10| 35000|\n",
      "| Sneha| 32|        10| 35000|\n",
      "|Anaaya|  4|         0|     0|\n",
      "|Sayali| 28|         5| 25000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb2ebfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|  Rohit|  32|        10| 35000|\n",
      "|  Sneha|  32|        10| 35000|\n",
      "| Anaaya|   4|         0|     0|\n",
      "| Sayali|  28|         5| 25000|\n",
      "|   null|  56|        35| 50000|\n",
      "| Shobha|null|      null|  null|\n",
      "|Harshad|null|      null| 10000|\n",
      "| Milind|  35|         5|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### how = all\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8da8040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Rohit| 32|        10| 35000|\n",
      "| Sneha| 32|        10| 35000|\n",
      "|Anaaya|  4|         0|     0|\n",
      "|Sayali| 28|         5| 25000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### how = all\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bf9c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|  Rohit|  32|        10| 35000|\n",
      "|  Sneha|  32|        10| 35000|\n",
      "| Anaaya|   4|         0|     0|\n",
      "| Sayali|  28|         5| 25000|\n",
      "|   null|  56|        35| 50000|\n",
      "|Harshad|null|      null| 10000|\n",
      "| Milind|  35|         5|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###threshold\n",
    "df_pyspark.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60425fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|experience|Salary|\n",
      "+------+---+----------+------+\n",
      "| Rohit| 32|        10| 35000|\n",
      "| Sneha| 32|        10| 35000|\n",
      "|Anaaya|  4|         0|     0|\n",
      "|Sayali| 28|         5| 25000|\n",
      "|  null| 56|        35| 50000|\n",
      "|Milind| 35|         5|  null|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###subset\n",
    "df_pyspark.na.drop(how='any',subset=['experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da504ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Rohit| 32|        10| 35000|\n",
      "|  Sneha| 32|        10| 35000|\n",
      "| Anaaya|  4|         0|     0|\n",
      "| Sayali| 28|         5| 25000|\n",
      "|   null| 56|        35| 50000|\n",
      "| Shobha|  0|         0|     0|\n",
      "|Harshad|  0|         0| 10000|\n",
      "| Milind| 35|         5|     0|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Fill Missing value \n",
    "df_pyspark.na.fill(0,['experience','age','Salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a325d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|  Rohit|  32|        10| 35000|\n",
      "|  Sneha|  32|        10| 35000|\n",
      "| Anaaya|   4|         0|     0|\n",
      "| Sayali|  28|         5| 25000|\n",
      "|   null|  56|        35| 50000|\n",
      "| Shobha|null|      null|  null|\n",
      "|Harshad|null|      null| 10000|\n",
      "| Milind|  35|         5|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2f6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74e8a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols=['Age','experience','Salary'],\n",
    "    outputCols= [\"{}_imputed\".format(c) for c in ['Age','experience','Salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7a90dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Name| Age|experience|Salary|Age_imputed|experience_imputed|Salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Rohit|  32|        10| 35000|         32|                10|         35000|\n",
      "|  Sneha|  32|        10| 35000|         32|                10|         35000|\n",
      "| Anaaya|   4|         0|     0|          4|                 0|             0|\n",
      "| Sayali|  28|         5| 25000|         28|                 5|         25000|\n",
      "|   null|  56|        35| 50000|         56|                35|         50000|\n",
      "| Shobha|null|      null|  null|         31|                10|         25833|\n",
      "|Harshad|null|      null| 10000|         31|                10|         10000|\n",
      "| Milind|  35|         5|  null|         35|                 5|         25833|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96441e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
